{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a448649",
   "metadata": {},
   "source": [
    "# Reflexion Pattern with OpenAI: CSV Data Analysis\n",
    "\n",
    "In this notebook, we show the **Reflexion** pattern for CSV data analysis. The agent:\n",
    "1. **Generates code** to analyze a CSV (via OpenAI).\n",
    "2. **Executes** the code locally.\n",
    "3. If there's an error, the agent sends the **error message** to OpenAI, gets a **corrected** snippet, and **retries**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25109ec",
   "metadata": {},
   "source": [
    "## 1. Data Executor\n",
    "We use a **controlled environment** to run user-generated Python code. In reality, you'd want more robust sandboxing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cfab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def run_generated_code(code_str, csv_data):\n",
    "    \"\"\"\n",
    "    Executes the user-generated Python code in a controlled environment.\n",
    "    Returns (success, result_or_error).\n",
    "    - success = True if code ran without exception\n",
    "    - result_or_error = code's return value or error message\n",
    "    \"\"\"\n",
    "    local_env = {\n",
    "        \"pd\": pd,\n",
    "        \"csv_data\": csv_data,\n",
    "        \"io\": io,\n",
    "        \"result\": None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        exec(code_str, {}, local_env)\n",
    "        return True, local_env.get(\"result\", \"No result variable found.\")\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cebf2c",
   "metadata": {},
   "source": [
    "## 2. OpenAI Adapter (Reflexion)\n",
    "We create a function `call_openai_for_code` that:\n",
    "- Takes in **prompt** (e.g., “User Query: …” or “REFLECT_ON_ERROR: …”).\n",
    "- Calls the **OpenAI** client.\n",
    "- Returns the **code snippet** from `.choices[0].message.content`.\n",
    "\n",
    "We’ll assume the user wants the model `gpt-4o` (or whatever custom name you have) and a short `developer` message to keep context. In practice, you’ll adapt the system/developer/user messages as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcccc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=''\n",
    "\n",
    "\n",
    "# Initialize your client (ensure your environment has OPENAI_API_KEY set, or provide it explicitly)\n",
    "client = OpenAI()\n",
    "\n",
    "def call_openai_for_code(prompt, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI chat completion endpoint with a developer/system message and a user message.\n",
    "    Expects the LLM to return a Python code snippet.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"developer\", \"content\": \"You are a helpful code-generation assistant. give only code.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # or 'gpt-3.5-turbo' or another model\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    code_snippet = completion.choices[0].message.content\n",
    "    code_snippet = clean_code(code_snippet)\n",
    "    print (code_snippet)\n",
    "    return code_snippet.strip()\n",
    "\n",
    "# Function to clean up code (remove markdown formatting like ```python and `python`)\n",
    "def clean_code(code):\n",
    "    # Remove any markdown code fences (```) and 'python' marker\n",
    "    if code.startswith(\"```\"):\n",
    "        # Split by ``` and take the code in between, while also stripping 'python' if it appears after ```\n",
    "        code = code.split(\"```\")[1]\n",
    "    \n",
    "    # Remove any remaining 'python' marker if it starts the cleaned block\n",
    "    code = code.replace(\"python\", \"\").strip()\n",
    "    \n",
    "    return code.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840f08ff",
   "metadata": {},
   "source": [
    "## 3. CSV Reflexion Agent\n",
    "Implements the **Reflexion** loop:\n",
    "1. Generate initial code from the user query (via `call_openai_for_code`).\n",
    "2. Execute. If error, reflect with the error message, get corrected code.\n",
    "3. Return final result or error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd5675",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVReflexionAgent:\n",
    "    def __init__(self, csv_data, max_reflections=2):\n",
    "        self.csv_data = csv_data\n",
    "        self.max_reflections = max_reflections\n",
    "        self.conversation_log = []\n",
    "\n",
    "    def analyze_query(self, user_query: str):\n",
    "        initial_prompt = (\n",
    "            f\"User Query: {user_query}\\n\"\n",
    "            \"You have a pandas DataFrame named 'csv_data'. Generate Python code to achieve the user's goal.\\n\"\n",
    "            \"Store the final result in 'result'.\"\n",
    "        )\n",
    "\n",
    "        # 1) Get initial code from OpenAI\n",
    "        code_snippet = call_openai_for_code(initial_prompt)\n",
    "        self.conversation_log.append(f\"Initial code:\\n{code_snippet}\\n\")\n",
    "\n",
    "        success, outcome = run_generated_code(code_snippet, self.csv_data)\n",
    "\n",
    "        reflections = 0\n",
    "        while not success and reflections < self.max_reflections:\n",
    "            reflections += 1\n",
    "            error_msg = outcome\n",
    "            self.conversation_log.append(f\"Error: {error_msg}\\n\")\n",
    "\n",
    "            # 2) Reflection prompt\n",
    "            reflection_prompt = (\n",
    "                f\"REFLECT_ON_ERROR: The code failed with error:\\n{error_msg}\\n\"\n",
    "                \"Please correct the code so it works.\"  # Brief instruction\n",
    "            )\n",
    "\n",
    "            corrected_code = call_openai_for_code(reflection_prompt)\n",
    "            self.conversation_log.append(f\"Corrected code:\\n{corrected_code}\\n\")\n",
    "\n",
    "            success, outcome = run_generated_code(corrected_code, self.csv_data)\n",
    "\n",
    "        # Final check\n",
    "        if success:\n",
    "            if outcome is None or (hasattr(outcome, \"empty\") and outcome.empty):\n",
    "                self.conversation_log.append(\"Result is empty. Possibly unsatisfactory.\")\n",
    "                return \"No meaningful data produced.\"\n",
    "            else:\n",
    "                return outcome\n",
    "        else:\n",
    "            self.conversation_log.append(\"Exceeded max reflections. No solution.\")\n",
    "            return \"Sorry, couldn't generate valid code.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032f055",
   "metadata": {},
   "source": [
    "## 4. Main Orchestration\n",
    "Here, we create some dummy CSV data, instantiate the **Reflexion agent**, and run a sample query like “Please sum the 'Value' column by 'Category'.” We then print out the final result (or error) plus the conversation log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3131b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example CSV Data\n",
    "    sample_data = {\n",
    "        \"Category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\"],\n",
    "        \"Value\": [10, 5, 3, 8, 2, 6],\n",
    "        \"Comment\": [\"foo\", \"bar\", \"baz\", \"lorem\", \"ipsum\", \"dolor\"]\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(sample_data)\n",
    "\n",
    "    # Create the agent\n",
    "    agent = CSVReflexionAgent(csv_data=df, max_reflections=2)\n",
    "\n",
    "    # User's data analysis request\n",
    "    user_query = \"Please sum the 'Value' column by 'Category'.\"\n",
    "\n",
    "    # Let the agent handle it\n",
    "    result = agent.analyze_query(user_query)\n",
    "\n",
    "    print(\"=== Final Analysis Result ===\")\n",
    "    print(result)\n",
    "\n",
    "    print(\"\\n=== Conversation Log ===\")\n",
    "    for entry in agent.conversation_log:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc83990",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "1. **Install** `openai` and set your `OPENAI_API_KEY` environment variable, or configure `client = OpenAI(api_key=\"...\")`.\n",
    "2. **Run all cells**. The final cell will demonstrate a sample user query. If the initial code fails, the agent tries up to 2 reflections.\n",
    "3. The outcome might be something like a `pandas.Series` or `DataFrame` grouping result (e.g., sums by category).\n",
    "4. Inspect the `conversation_log` for each step of code generation and error correction.\n",
    "\n",
    "## Key Points\n",
    "- **Reflexion**: We feed errors back to the LLM so it can correct the generated code.\n",
    "- **Sandbox**: We just do a local `exec()`. In real applications, consider safer isolation.\n",
    "- **Single** or **Multiple** Reflection Steps: We limit to `max_reflections=2` to avoid infinite loops.\n",
    "- **Prompt Engineering**: You can refine the system/developer messages for more specialized code generation or debugging instructions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "reflexion_csv_demo_openai"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
