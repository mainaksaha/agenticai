{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce7b9c1",
   "metadata": {},
   "source": [
    "# Reflexion Pattern Demo: CSV Data Analysis\n",
    "\n",
    "This notebook demonstrates a **Reflexion** pattern with an AI agent:\n",
    "- The agent generates **dynamic Python code** to analyze CSV/Excel data.\n",
    "- It **executes** that code in a controlled environment.\n",
    "- If there's an **error or unsatisfactory result**, the agent **reflects** on it and **self-corrects** the code.\n",
    "\n",
    "We’ll organize the code into **four sections**:\n",
    "1. **Data Executor** (executes generated Python code safely)\n",
    "2. **LLM Adapter** (a mock function to simulate LLM behavior)\n",
    "3. **CSV Reflexion Agent** (the core logic that orchestrates code generation, execution, and correction)\n",
    "4. **Main Orchestration** (loads sample data and runs the agent)\n",
    "\n",
    "In a real system, you would use a more robust sandbox for code execution, integrate a genuine LLM API, and add more sophisticated error handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66033f3d",
   "metadata": {},
   "source": [
    "## Section 1: Data Executor\n",
    "This module simulates a **controlled environment** to execute user-generated Python code strings. We expose:\n",
    "- `pd` (pandas)\n",
    "- `csv_data` (the DataFrame)\n",
    "- `io` (for potential I/O)\n",
    "- A placeholder variable `result` which the code can set.\n",
    "\n",
    "In production, you’d replace this with a true sandbox (Docker, restricted interpreter, etc.) for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31b9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_executor.py\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def run_generated_code(code_str, csv_data):\n",
    "    \"\"\"\n",
    "    Executes the user-generated Python code in a controlled environment.\n",
    "    Returns (success, result_or_error).\n",
    "    - success = True if code ran without exception\n",
    "    - result_or_error = code's return value or error message\n",
    "    \"\"\"\n",
    "    # Restricted local environment for exec\n",
    "    local_env = {\n",
    "        \"pd\": pd,\n",
    "        \"csv_data\": csv_data,\n",
    "        \"io\": io,\n",
    "        \"result\": None,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        exec(code_str, {}, local_env)\n",
    "        # Expecting the code to set 'result' if it wants to return something\n",
    "        return True, local_env.get(\"result\", \"No result variable found.\")\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98bb82",
   "metadata": {},
   "source": [
    "## Section 2: LLM Adapter\n",
    "Here, we define a **mock** LLM call function (`call_llm`). In a real environment, this would be replaced by calls to an actual LLM API (e.g., OpenAI, Anthropic). For demonstration, it returns either an initial code snippet or a “corrected” snippet if it detects a reflection prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43231a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_adapter.py\n",
    "\n",
    "def call_llm(prompt, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Simulated LLM call. If 'REFLECT_ON_ERROR' is in the prompt, we return a 'corrected' snippet.\n",
    "    Otherwise, we return an initial code snippet.\n",
    "    \"\"\"\n",
    "    if \"REFLECT_ON_ERROR:\" in prompt:\n",
    "        # LLM sees an error and attempts a fix\n",
    "        return (\n",
    "            \"# Corrected code snippet:\\n\"\n",
    "            \"import pandas as pd\\n\"\n",
    "            \"result = csv_data.groupby('Category')['Value'].sum()\\n\"\n",
    "        )\n",
    "    else:\n",
    "        # First attempt code snippet\n",
    "        return (\n",
    "            \"# Generated code snippet:\\n\"\n",
    "            \"import pandas as pd\\n\"\n",
    "            \"# Let's assume we want to group by 'Category' and calculate sum of 'Value'\\n\"\n",
    "            \"result = csv_data.groupby('Category')['Value'].sum()\\n\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcace2",
   "metadata": {},
   "source": [
    "## Section 3: CSV Reflexion Agent\n",
    "This class handles the **Reflexion** loop:\n",
    "1. Prompt the LLM for code.\n",
    "2. **Execute** the code.\n",
    "3. If there’s an error, create a **reflection prompt** with the error and get corrected code.\n",
    "4. Retry until success or until hitting a maximum number of reflections.\n",
    "\n",
    "Optionally, we can also check if the result is \"satisfactory\" (not empty, not None, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756c006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_reflexion_agent.py\n",
    "\n",
    "from llm_adapter import call_llm\n",
    "from data_executor import run_generated_code\n",
    "\n",
    "class CSVReflexionAgent:\n",
    "    def __init__(self, csv_data, max_reflections=2):\n",
    "        \"\"\"\n",
    "        :param csv_data: A pandas DataFrame\n",
    "        :param max_reflections: How many times to allow auto-correction\n",
    "        \"\"\"\n",
    "        self.csv_data = csv_data\n",
    "        self.max_reflections = max_reflections\n",
    "        self.conversation_log = []\n",
    "\n",
    "    def analyze_query(self, user_query: str):\n",
    "        \"\"\"\n",
    "        Main method:\n",
    "        1. Prompt LLM for code.\n",
    "        2. Execute.\n",
    "        3. If error, reflect.\n",
    "        4. Return final result or error message.\n",
    "        \"\"\"\n",
    "        # Step 1: Initial code generation\n",
    "        initial_prompt = (\n",
    "            f\"User Query: {user_query}\\n\"\n",
    "            \"You have a pandas DataFrame called 'csv_data'. Generate Python code to achieve the user's goal.\\n\"\n",
    "            \"The code should store the final result in a variable named 'result'.\"\n",
    "        )\n",
    "\n",
    "        code_snippet = call_llm(initial_prompt)\n",
    "        self.conversation_log.append(f\"Initial code:\\n{code_snippet}\\n\")\n",
    "\n",
    "        success, outcome = run_generated_code(code_snippet, self.csv_data)\n",
    "\n",
    "        reflections = 0\n",
    "        while not success and reflections < self.max_reflections:\n",
    "            reflections += 1\n",
    "            error_msg = outcome\n",
    "            self.conversation_log.append(f\"Execution error: {error_msg}\\n\")\n",
    "\n",
    "            # Step 2: Reflection prompt\n",
    "            reflection_prompt = (\n",
    "                f\"REFLECT_ON_ERROR: The code failed with the following error:\\n{error_msg}\\n\"\n",
    "                \"Please correct the code.\"\n",
    "            )\n",
    "            corrected_code = call_llm(reflection_prompt)\n",
    "            self.conversation_log.append(f\"Corrected code:\\n{corrected_code}\\n\")\n",
    "\n",
    "            success, outcome = run_generated_code(corrected_code, self.csv_data)\n",
    "\n",
    "        # If success, check if outcome is meaningful\n",
    "        if success:\n",
    "            if outcome is None or (hasattr(outcome, \"empty\") and outcome.empty):\n",
    "                self.conversation_log.append(\"The result is empty or None. Possibly unsatisfactory.\\n\")\n",
    "                return \"No meaningful data was produced by the analysis.\"\n",
    "            else:\n",
    "                return outcome\n",
    "        else:\n",
    "            # Even after max reflections, we failed\n",
    "            self.conversation_log.append(\"Exceeded max reflections. No solution found.\\n\")\n",
    "            return \"Sorry, I couldn't generate a valid code snippet.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efafcd",
   "metadata": {},
   "source": [
    "## Section 4: Main Orchestration\n",
    "We simulate loading some CSV data (here, we just create a small DataFrame in-memory). We then instantiate the **CSVReflexionAgent** and provide a user query (e.g., \"Please sum the 'Value' column by 'Category'.\")\n",
    "\n",
    "Run the final cell and observe the result, along with any **reflection** steps if an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c211546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import pandas as pd\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data simulating CSV contents\n",
    "    sample_data = {\n",
    "        \"Category\": [\"A\", \"B\", \"A\", \"C\", \"B\", \"A\"],\n",
    "        \"Value\": [10, 5, 3, 8, 2, 6],\n",
    "        \"Comment\": [\"foo\", \"bar\", \"baz\", \"lorem\", \"ipsum\", \"dolor\"]\n",
    "    }\n",
    "    df = pd.DataFrame(sample_data)\n",
    "\n",
    "    # Instantiate our Reflexion-based agent\n",
    "    from csv_reflexion_agent import CSVReflexionAgent\n",
    "    agent = CSVReflexionAgent(csv_data=df, max_reflections=2)\n",
    "\n",
    "    # User query\n",
    "    user_query = \"Please sum the 'Value' column by 'Category'.\"\n",
    "\n",
    "    # Analyze the query\n",
    "    final_result = agent.analyze_query(user_query)\n",
    "\n",
    "    print(\"=== Final Analysis Result ===\")\n",
    "    print(final_result)\n",
    "    print(\"\\n=== Conversation Log ===\")\n",
    "    for entry in agent.conversation_log:\n",
    "        print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9aff95",
   "metadata": {},
   "source": [
    "## How to Run\n",
    "1. **Run all cells** in this notebook.\n",
    "2. Observe the **Final Analysis Result**. If the first code snippet works, the agent won't need to reflect. If there's an error, you'll see a **reflection** attempt.\n",
    "\n",
    "## Key Takeaways\n",
    "1. **Reflexion Loop**: The agent tries some code, checks if it fails or is unsatisfactory, then **reflects** with an error prompt to produce a corrected version.\n",
    "2. **Self-Correction**: The LLM sees the error details (exception message) and attempts to fix the code.\n",
    "3. **Sandboxing**: In production, you'd want a safer environment than a raw `exec()`. Docker containers, restricted interpreters, or frameworks like Jupyter’s `ipykernel` in a restricted mode can help.\n",
    "4. **Practical Use**: This can be extended for more complex data transformations, logic errors, or repeated improvement (like performance tuning, scaling to bigger data, etc.).\n",
    "5. **Limitations**: Ensure you have a maximum number of reflections, and that you handle any possible infinite loops or repetitive errors. In real systems, guard against malicious or resource-intensive code.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "reflexion_csv_demo"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
