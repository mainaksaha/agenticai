{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fb9e280",
   "metadata": {},
   "source": [
    "# ReAct Pattern with OpenAI\n",
    "\n",
    "This notebook demonstrates a **ReAct (Reason + Act) pattern** for an **airline refund** scenario, **using OpenAI** for the LLM calls:\n",
    "\n",
    "1. **Policy Logic** – Contains the airline’s refund rules.\n",
    "2. **OpenAI Adapter** – Our function to call OpenAI’s API (instead of a mock).\n",
    "3. **ReAct Agent** – Implements the Reason → Act → Observe → Conclude loop.\n",
    "4. **Main Orchestration** – Ties it all together to decide whether the passenger is eligible for a refund.\n",
    "\n",
    "We'll pass short prompts to OpenAI that mimic \"thinking\" (Reason) or \"tool usage\" (Act), and parse the results.\n",
    "\n",
    "## Requirements\n",
    "- `openai` Python package (`pip install openai`).\n",
    "- An **OpenAI API key** set in your environment (e.g., `OPENAI_API_KEY`).\n",
    "\n",
    "## Outline\n",
    "1. Policy logic for refunds.\n",
    "2. OpenAI LLM adapter.\n",
    "3. ReAct-based agent.\n",
    "4. A main cell to run the scenario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2feb28",
   "metadata": {},
   "source": [
    "## 1. Policy Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47e5a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=''\n",
    "\n",
    "\n",
    "\n",
    "AIRLINE_POLICIES = {\n",
    "    \"REFUND_WINDOW_HOURS\": 24,\n",
    "    \"NON_REFUNDABLE_CLASSES\": [\"BasicEconomy\"],\n",
    "    \"PARTIAL_REFUND_CLASSES\": [\"Economy\", \"PremiumEconomy\"],\n",
    "    \"FULL_REFUND_CLASSES\": [\"Business\", \"First\"]\n",
    "}\n",
    "\n",
    "def check_refund_eligibility(booking_time, cabin_class):\n",
    "    \"\"\"\n",
    "    Check if the flight is eligible for a refund based on booking time and cabin class.\n",
    "    Returns (eligible: bool, refund_amount: float)\n",
    "    \"\"\"\n",
    "    now = datetime.now()\n",
    "    time_since_booking = (now - booking_time).total_seconds() / 3600.0\n",
    "\n",
    "    # 1) Full refund if within 24 hours\n",
    "    if time_since_booking <= AIRLINE_POLICIES[\"REFUND_WINDOW_HOURS\"]:\n",
    "        return True, 1.0\n",
    "\n",
    "    # 2) Check class rules\n",
    "    if cabin_class in AIRLINE_POLICIES[\"NON_REFUNDABLE_CLASSES\"]:\n",
    "        return False, 0.0\n",
    "    elif cabin_class in AIRLINE_POLICIES[\"FULL_REFUND_CLASSES\"]:\n",
    "        return True, 1.0\n",
    "    elif cabin_class in AIRLINE_POLICIES[\"PARTIAL_REFUND_CLASSES\"]:\n",
    "        return True, 0.5\n",
    "\n",
    "    return False, 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60eacc3a",
   "metadata": {},
   "source": [
    "## 2. OpenAI LLM Adapter\n",
    "We define a **`call_openai`** function that:\n",
    "- Sends a **prompt** to OpenAI (using the `gpt-3.5-turbo` model).\n",
    "- Returns the **text** from the model's response.\n",
    "\n",
    "We keep it simple. In a real application, you'd incorporate more robust logic (e.g., using function calling, better prompt engineering, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c0295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(prompt, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI ChatCompletion API with the given prompt.\n",
    "    Returns the response text.\n",
    "    \"\"\"\n",
    "    system_message = \"You are a helpful AI for airline refunds.\"\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    response =client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "        max_tokens=150,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message.content\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858a594",
   "metadata": {},
   "source": [
    "## 3. ReAct Agent\n",
    "We implement the same **ReAct** flow:\n",
    "1. **Reason** – e.g., “Step 1: we need to check airline policy.”\n",
    "2. **Act** – call the `check_refund_eligibility` tool.\n",
    "3. **Observe** – see the result of that tool.\n",
    "4. **Reason again** – possibly finalize.\n",
    "5. **Conclude** – produce the final user-facing result.\n",
    "\n",
    "Here, we show short prompts to OpenAI that represent these steps. In a real system, you might structure these carefully or parse partial chain-of-thought. For demonstration, we keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e94d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReActAirlineAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_log = []\n",
    "\n",
    "    def handle_refund_request(self, booking_time, cabin_class):\n",
    "        \"\"\"\n",
    "        Demonstrates ReAct with OpenAI calls.\n",
    "        1) reason (short prompt)\n",
    "        2) call tool\n",
    "        3) feed observation, reason again\n",
    "        4) produce final answer\n",
    "        \"\"\"\n",
    "        # 1) Reason step with the LLM\n",
    "        reason_prompt = (\n",
    "            \"The user wants a refund.\\n\"\n",
    "            \"Step 1: We need to check airline policy.\\n\"\n",
    "            \"Action: CallPolicyTool\\n\"\n",
    "        )\n",
    "        thought_response = call_openai(reason_prompt)\n",
    "        self.conversation_log.append(f\"Thought: {thought_response}\")\n",
    "\n",
    "        # 2) Actually call the policy function\n",
    "        eligible, ratio = check_refund_eligibility(booking_time, cabin_class)\n",
    "        observation_text = f\"Observation: policy says eligible={eligible}, ratio={ratio}\"\n",
    "        self.conversation_log.append(observation_text)\n",
    "\n",
    "        # 3) Provide observation to LLM and ask for conclusion\n",
    "        second_prompt = (\n",
    "            \"We have the following observation from the policy tool:\\n\"\n",
    "            f\"{observation_text}\\n\"\n",
    "            \"Now decide the final outcome.\\n\"\n",
    "            \"Action: SummarizeRefund\\n\"\n",
    "        )\n",
    "        second_response = call_openai(second_prompt)\n",
    "        self.conversation_log.append(f\"Thought: {second_response}\")\n",
    "\n",
    "        # 4) Formulate final user-facing answer\n",
    "        if eligible:\n",
    "            refund_amount = f\"{int(ratio * 100)}%\"\n",
    "            final_decision = f\"Approved for a refund of {refund_amount} of the ticket price.\"\n",
    "        else:\n",
    "            final_decision = \"Not eligible for a refund.\"\n",
    "\n",
    "        # We might do one more LLM call to get a stylized message, but let's keep it simple.\n",
    "\n",
    "        user_answer = (\n",
    "            \"Thank you for contacting Airline Support.\\n\"\n",
    "            f\"After reviewing your booking, you are: {final_decision}\\n\"\n",
    "        )\n",
    "\n",
    "        return user_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe6bf99",
   "metadata": {},
   "source": [
    "## 4. Main Orchestration\n",
    "We simulate a user booking 30 hours ago in **Economy** class. We'll see how the ReAct agent interacts with OpenAI for reasoning steps, calls the policy function, and returns a final outcome.\n",
    "\n",
    "Change the booking time or cabin class to see different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # E.g., booked 30 hours ago\n",
    "    booking_time = datetime.now() - timedelta(hours=30)\n",
    "    cabin_class = \"Economy\"\n",
    "\n",
    "    agent = ReActAirlineAgent()\n",
    "    final_msg = agent.handle_refund_request(booking_time, cabin_class)\n",
    "    print(\"=== FINAL USER-FACING MESSAGE ===\")\n",
    "    print(final_msg)\n",
    "\n",
    "    # If you'd like to see the agent's internal conversation:\n",
    "    # for log_entry in agent.conversation_log:\n",
    "    #     print(log_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2976591a",
   "metadata": {},
   "source": [
    "## Running the Notebook\n",
    "1. **Set your OpenAI key** (e.g., `export OPENAI_API_KEY=sk-...`) or add `openai.api_key = \"YOUR_KEY\"` in code.\n",
    "2. **Run all cells**.\n",
    "3. Observe the final user-facing message.\n",
    "\n",
    "You can also inspect the `agent.conversation_log` to see the partial LLM responses that represent \"thinking.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51528e57-a0fb-4ef4-abaf-62d739cdf567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "react_airline_demo_openai"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
