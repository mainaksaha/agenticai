{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3fd8e95",
   "metadata": {},
   "source": [
    "# Auto-GPT Style Agent with Explicit CoT (Single-File, No web_tools Install)\n",
    "\n",
    "This notebook shows how you can implement an **Auto-GPT** style agent with explicit **Chain-of-Thought** in a **single file**, **no** external package like `web_tools` needed:\n",
    "\n",
    "1. **Inline Web Tools**: We define a dummy `web_search_tool` and `web_scrape_tool` as normal Python functions.\n",
    "2. **OpenAI CoT Adapter**: We use the `openai` library to call your LLM model.\n",
    "3. **Auto-GPT CoT Agent**: Repeatedly calls the LLM to see if a `FINAL_ANSWER` is ready or if we need to **PLAN_TO_VISIT** certain sites.\n",
    "4. **Main**: Runs the scenario with a user query.\n",
    "\n",
    "We **mock** two sites:\n",
    "- `review_evs.com` – Contains user sentiment data.\n",
    "- `auto_market.com` – Contains approximate pricing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a728a",
   "metadata": {},
   "source": [
    "## 1. Inline “Web Tools”\n",
    "We define two Python functions:\n",
    "- `web_search_tool(query)`: returns a **list** of relevant site URLs\n",
    "- `web_scrape_tool(url)`: returns **text content** from that site\n",
    "\n",
    "No extra installation needed. We just store data in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354b420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MOCK_WEBSITES = {\n",
    "    \"review_evs.com\": (\n",
    "        \"Buyer Sentiment Summary:\\n\"\n",
    "        \" - Tesla Model Y: Highly rated by most users, praising range and performance.\\n\"\n",
    "        \" - Nissan Leaf: Moderate reviews, good for city driving but limited range.\\n\"\n",
    "        \" - E-Car Pro: Newer entrant, positive early feedback on interior.\\n\"\n",
    "        \"Overall, the top-rated EV by user sentiment is the Tesla Model Y.\"\n",
    "    ),\n",
    "    \"auto_market.com\": (\n",
    "        \"Pricing Data:\\n\"\n",
    "        \" - Tesla Model Y: Starting at $54,000.\\n\"\n",
    "        \" - Nissan Leaf: Starting at $28,000.\\n\"\n",
    "        \" - E-Car Pro: Starting at $39,000.\\n\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def web_search_tool(query):\n",
    "    \"\"\"\n",
    "    Returns a list of site URLs based on the keywords in `query`.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    ql = query.lower()\n",
    "    if \"review\" in ql or \"sentiment\" in ql:\n",
    "        results.append(\"review_evs.com\")\n",
    "    if \"price\" in ql or \"market\" in ql:\n",
    "        results.append(\"auto_market.com\")\n",
    "    # fallback\n",
    "    if not results:\n",
    "        results.append(\"review_evs.com\")\n",
    "    return results\n",
    "\n",
    "def web_scrape_tool(url):\n",
    "    \"\"\"\n",
    "    Returns mock text content for a site.\n",
    "    \"\"\"\n",
    "    return MOCK_WEBSITES.get(url, \"No content for this URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf1179e",
   "metadata": {},
   "source": [
    "## 2. OpenAI CoT Adapter\n",
    "We define a function that calls **OpenAI** for chain-of-thought. It concatenates the conversation log into a single user message, then returns the LLM’s answer.\n",
    "\n",
    "**Note**: Make sure you have `openai` installed (`pip install openai`) and your environment variable `OPENAI_API_KEY` set, or pass an API key in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d560a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=''\n",
    "\n",
    "\n",
    "def call_openai_for_cot(conversation, model=\"gpt-4o\", temperature=0.2):\n",
    "    \"\"\"\n",
    "    Calls OpenAI to get chain-of-thought or final answer.\n",
    "    The conversation is a list of strings.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an Auto-GPT style agent with explicit chain-of-thought.\"},\n",
    "        {\"role\": \"user\", \"content\": \"\\n\".join(conversation)}\n",
    "    ]\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=300,\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2266e0",
   "metadata": {},
   "source": [
    "## 3. Auto-GPT CoT Agent\n",
    "This agent:\n",
    "1. Maintains `conversation_log`.\n",
    "2. Each iteration, calls `call_openai_for_cot` with the entire log.\n",
    "3. If it finds `FINAL_ANSWER:`, it returns.\n",
    "4. If it finds `PLAN_TO_VISIT: [ ... ]`, it extracts keywords, calls `web_search_tool`, then `web_scrape_tool`, and appends results.\n",
    "5. Continues until `max_iterations` is reached or we get a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305b5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoGPTCoTAgent:\n",
    "    def __init__(self, max_iterations=5, model=\"gpt-4o\"):\n",
    "        self.conversation_log = []\n",
    "        self.visited_sites = set()\n",
    "        self.max_iterations = max_iterations\n",
    "        self.model = model\n",
    "\n",
    "    def run(self, user_query):\n",
    "        # Add user query to the conversation\n",
    "        self.conversation_log.append(f\"User: {user_query}\")\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            # 1) Call OpenAI for chain-of-thought\n",
    "            llm_response = call_openai_for_cot(self.conversation_log, model=self.model)\n",
    "            self.conversation_log.append(f\"Agent: {llm_response}\")\n",
    "\n",
    "            # 2) Check if we have FINAL_ANSWER\n",
    "            if \"FINAL_ANSWER:\" in llm_response:\n",
    "                answer_text = llm_response.split(\"FINAL_ANSWER:\")[-1].strip()\n",
    "                return answer_text\n",
    "\n",
    "            # 3) Check for PLAN_TO_VISIT:\n",
    "            match = re.search(r\"PLAN_TO_VISIT:\\s*\\[(.*?)\\]\", llm_response)\n",
    "            if match:\n",
    "                plan_str = match.group(1)\n",
    "                # e.g. \"review sentiment\" or \"price market\"\n",
    "                keywords = [k.strip() for k in plan_str.split(\",\")]\n",
    "\n",
    "                for kw in keywords:\n",
    "                    # web search\n",
    "                    sites = web_search_tool(kw)\n",
    "                    self.conversation_log.append(f\"System: Searching for '{kw}' -> {sites}\")\n",
    "\n",
    "                    for site in sites:\n",
    "                        if site not in self.visited_sites:\n",
    "                            content = web_scrape_tool(site)\n",
    "                            self.visited_sites.add(site)\n",
    "                            self.conversation_log.append(f\"System: SCRAPED {site} -> {content}\")\n",
    "            else:\n",
    "                # no plan found, we just continue\n",
    "                self.conversation_log.append(\"System: No plan found. Continuing.\")\n",
    "\n",
    "        return \"Sorry, couldn't complete the research in time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9341ff68",
   "metadata": {},
   "source": [
    "## 4. Main Orchestration\n",
    "Finally, we provide the user query: \"Find the price of the best EV in the market based on buyer sentiment.\" The agent attempts to gather enough info from the dummy websites, then produce a final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    user_query = \"Find the price of the best EV in the market based on buyer sentiment.\"\n",
    "    agent = AutoGPTCoTAgent(max_iterations=5, model=\"gpt-4o\")\n",
    "    final_answer = agent.run(user_query)\n",
    "\n",
    "    print(\"=== FINAL ANSWER ===\")\n",
    "    print(final_answer)\n",
    "    \n",
    "    # Uncomment to see the conversation log:\n",
    "    for line in agent.conversation_log:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05336bc3",
   "metadata": {},
   "source": [
    "## How to Run\n",
    "1. **Save** this file as `auto_gpt_cot_demo_singlefile.ipynb`.\n",
    "2. **Install** `openai` via `pip install openai`.\n",
    "3. **Set** `OPENAI_API_KEY` in your environment or do `openai.api_key = \"<your_key>\"` in code.\n",
    "4. **Run all cells**. The last cell attempts to iterate until it finds a final answer or hits `max_iterations`.\n",
    "\n",
    "## Notes\n",
    "1. **No** separate `web_tools` install—just local Python functions.\n",
    "2. **Chain-of-Thought** is an **explicit** style: we prompt the LLM to produce lines like `CHAIN_OF_THOUGHT:` and `PLAN_TO_VISIT:` or `FINAL_ANSWER:`.\n",
    "3. **Dummy** data for websites. In production, you'd fetch real data from the web or a knowledge store.\n",
    "4. You may need to refine the prompt for your actual LLM usage, especially if it doesn't consistently follow the `PLAN_TO_VISIT` or `FINAL_ANSWER` pattern.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "auto_gpt_cot_demo_singlefile"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
