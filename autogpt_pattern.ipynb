{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "983aed37",
   "metadata": {},
   "source": [
    "# Auto-GPT Style Agent with Explicit Chain-of-Thought (CoT)\n",
    "\n",
    "This notebook demonstrates a simplified **Auto-GPT** flow in which the agent **plans** its steps via **Chain-of-Thought (CoT)**. The user query:\n",
    "> **“Find the price of the best EV in the market based on buyer sentiment.”**\n",
    "\n",
    "The agent’s process:\n",
    "1. **Identify** the need to determine buyer sentiment from a review site.\n",
    "2. **Scrape** the review site to figure out which EV is top-rated.\n",
    "3. **Scrape** an auto marketplace site for pricing details.\n",
    "4. **Provide** a final answer combining both details.\n",
    "\n",
    "We’ll break the code into **four sections**:\n",
    "1. **Web Tools** (Mocks site data and provides search/scrape functions)\n",
    "2. **LLM Adapter** (Mock LLM that returns explicit chain-of-thought steps)\n",
    "3. **Auto-GPT Style Agent** (Main loop that parses chain-of-thought, visits sites, and decides when to finalize)\n",
    "4. **Main Orchestration** (Runs the scenario with a user query)\n",
    "\n",
    "We'll show how the LLM's output includes:\n",
    "- **`CHAIN_OF_THOUGHT:`** for step-by-step reasoning.\n",
    "- **`PLAN_TO_VISIT:`** to decide which sites/tools to call.\n",
    "- **`FINAL_ANSWER:`** once it has enough data to respond.\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87981450",
   "metadata": {},
   "source": [
    "## Section 1: Web Tools\n",
    "We simulate two websites:\n",
    "- **review_evs.com**: buyer sentiment (which EV is top-rated).\n",
    "- **auto_market.com**: pricing data for certain EVs.\n",
    "\n",
    "We define:\n",
    "- `web_search_tool(query)`: a mock function that returns relevant sites based on keywords.\n",
    "- `web_scrape_tool(url)`: returns the site content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bcd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# web_tools.py\n",
    "\n",
    "# Mock data: websites and their content\n",
    "MOCK_WEBSITES = {\n",
    "    \"review_evs.com\": (\n",
    "        \"Buyer Sentiment Summary:\\n\"\n",
    "        \" - Tesla Model Y: Highly rated by most users, praising range and performance.\\n\"\n",
    "        \" - Nissan Leaf: Moderate reviews, good for city driving but limited range.\\n\"\n",
    "        \" - E-Car Pro: Newer entrant, positive early feedback on interior.\\n\"\n",
    "        \"Overall, the top-rated EV by user sentiment is the Tesla Model Y.\"\n",
    "    ),\n",
    "    \"auto_market.com\": (\n",
    "        \"Pricing Data:\\n\"\n",
    "        \" - Tesla Model Y: Starting at $54,000.\\n\"\n",
    "        \" - Nissan Leaf: Starting at $28,000.\\n\"\n",
    "        \" - E-Car Pro: Starting at $39,000.\\n\"\n",
    "    )\n",
    "}\n",
    "\n",
    "def web_search_tool(query):\n",
    "    \"\"\"\n",
    "    Mock function to 'search' the web for relevant sites based on the query.\n",
    "    We'll just match query keywords to decide which sites to visit.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "\n",
    "    if \"review\" in query_lower or \"sentiment\" in query_lower:\n",
    "        results.append(\"review_evs.com\")\n",
    "    if \"price\" in query_lower or \"market\" in query_lower:\n",
    "        results.append(\"auto_market.com\")\n",
    "\n",
    "    # If no direct match, return a default site\n",
    "    if not results:\n",
    "        results.append(\"review_evs.com\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def web_scrape_tool(url):\n",
    "    \"\"\"\n",
    "    Mock function to fetch text content from a site.\n",
    "    \"\"\"\n",
    "    return MOCK_WEBSITES.get(url, \"No content found for this URL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29abf56",
   "metadata": {},
   "source": [
    "## Section 2: LLM Adapter\n",
    "Here, we implement a mock `call_llm` function that:\n",
    "- Parses the conversation log (lowercased).\n",
    "- Checks whether we already have the **review data** and **pricing data** in the log.\n",
    "- If yes, it produces a **final answer**.\n",
    "- Otherwise, it provides a **chain-of-thought** and a **plan** to visit sites.\n",
    "\n",
    "This simulates a **Chain-of-Thought** approach, where the LLM enumerates reasoning steps explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc1218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_adapter.py\n",
    "\n",
    "def call_llm(conversation, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Simulated LLM call that explicitly includes Chain-of-Thought for demonstration.\n",
    "    We inspect the conversation to see what's been scraped.\n",
    "    If we have both sentiment data and price data, we produce a final answer.\n",
    "    Otherwise, we produce a plan to visit more sites.\n",
    "    \"\"\"\n",
    "    full_text = \"\\n\".join(conversation).lower()\n",
    "\n",
    "    # Check if we have the review (sentiment) data\n",
    "    has_review_data = \"review_evs.com\" in full_text\n",
    "    # Check if we have the auto market site data\n",
    "    has_price_data = \"auto_market.com\" in full_text\n",
    "\n",
    "    # If we have both sentiment data and pricing, finalize\n",
    "    if has_review_data and has_price_data:\n",
    "        return (\n",
    "            \"CHAIN_OF_THOUGHT:\\n\"\n",
    "            \"1. I've identified the top-rated EV from buyer sentiment (Tesla Model Y).\\n\"\n",
    "            \"2. I've found the price on the auto_market.com site ($54,000).\\n\"\n",
    "            \"Therefore, I can form the final answer.\\n\"\n",
    "            \"FINAL_ANSWER: The best EV based on buyer sentiment is the Tesla Model Y, \"\n",
    "            \"which is priced around $54,000.\"\n",
    "        )\n",
    "\n",
    "    # Otherwise, generate chain-of-thought and a plan\n",
    "    chain_of_thought = [\n",
    "        \"1. The user wants the best EV by buyer sentiment AND its price.\",\n",
    "        \"2. First, gather sentiment data from a review site.\",\n",
    "        \"3. Then, gather pricing data from an auto marketplace site.\"\n",
    "    ]\n",
    "\n",
    "    # If we haven't visited the review site, plan to do that\n",
    "    if not has_review_data:\n",
    "        chain_of_thought.append(\"4. We still need to visit a review site to see buyer sentiment.\")\n",
    "        plan_str = \"[review sentiment]\"\n",
    "    elif has_review_data and not has_price_data:\n",
    "        chain_of_thought.append(\"4. We have buyer sentiment but still need pricing info.\")\n",
    "        plan_str = \"[price market]\"\n",
    "    else:\n",
    "        plan_str = \"[review sentiment, price market]\"  # fallback\n",
    "\n",
    "    return (\n",
    "        \"CHAIN_OF_THOUGHT:\\n\" +\n",
    "        \"\\n\".join(chain_of_thought) + \"\\n\" +\n",
    "        \"PLAN_TO_VISIT: \" + plan_str\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ee7d0",
   "metadata": {},
   "source": [
    "## Section 3: Auto-GPT Style Agent\n",
    "An **Auto-GPT** style loop:\n",
    "1. We have a conversation log where we store user queries, LLM responses, and any system messages.\n",
    "2. Each iteration, we **call** the LLM.\n",
    "3. If we see a `FINAL_ANSWER`, we **stop**.\n",
    "4. If we see `PLAN_TO_VISIT: [...]`, we parse the keywords, use a **web search** to get sites, then **scrape** them.\n",
    "5. We add the scraped content to the conversation and loop again until we have enough data.\n",
    "6. We limit the loop via `max_iterations` to avoid infinite cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f6e033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autogpt_agent.py\n",
    "\n",
    "import re\n",
    "from llm_adapter import call_llm\n",
    "from web_tools import web_search_tool, web_scrape_tool\n",
    "\n",
    "class AutoGPTCoTAgent:\n",
    "    def __init__(self, max_iterations=5):\n",
    "        self.conversation_log = []\n",
    "        self.visited_sites = set()\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def run(self, user_query):\n",
    "        # Add user query to log\n",
    "        self.conversation_log.append(f\"User: {user_query}\")\n",
    "\n",
    "        for _ in range(self.max_iterations):\n",
    "            # 1. Call the LLM with our conversation log\n",
    "            llm_response = call_llm(self.conversation_log)\n",
    "            self.conversation_log.append(f\"Agent: {llm_response}\")\n",
    "\n",
    "            # 2. Check for final answer\n",
    "            if \"FINAL_ANSWER:\" in llm_response:\n",
    "                final_answer = llm_response.split(\"FINAL_ANSWER:\")[-1].strip()\n",
    "                return final_answer\n",
    "\n",
    "            # 3. Otherwise parse \"PLAN_TO_VISIT:\" with a regex\n",
    "            match = re.search(r\"PLAN_TO_VISIT:\\s*\\[(.*?)\\]\", llm_response)\n",
    "            if match:\n",
    "                plan_str = match.group(1)\n",
    "                # e.g., \"review sentiment\" or \"price market\"\n",
    "                keywords = [kw.strip() for kw in plan_str.split(\",\")]\n",
    "\n",
    "                for kw in keywords:\n",
    "                    # 4. Use web_search_tool to find relevant sites\n",
    "                    sites = web_search_tool(kw)\n",
    "                    self.conversation_log.append(f\"System: Searching for '{kw}' -> {sites}\")\n",
    "\n",
    "                    # For each site, if not visited, scrape\n",
    "                    for site in sites:\n",
    "                        if site not in self.visited_sites:\n",
    "                            content = web_scrape_tool(site)\n",
    "                            self.visited_sites.add(site)\n",
    "                            # Add the scraped content to the conversation\n",
    "                            self.conversation_log.append(f\"System: SCRAPED {site} -> {content}\")\n",
    "            else:\n",
    "                # No plan found; might need more context or next iteration\n",
    "                self.conversation_log.append(\"System: No plan found, waiting for next step.\")\n",
    "\n",
    "        # If we exit without final answer\n",
    "        return \"Sorry, I couldn't complete this research in time.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb540dff",
   "metadata": {},
   "source": [
    "## Section 4: Main Orchestration\n",
    "We now instantiate our **AutoGPTCoTAgent**, pass the user query, and watch the agent's step-by-step chain-of-thought as it visits the review site and then the marketplace site, finally returning the requested price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8d1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "from autogpt_agent import AutoGPTCoTAgent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"Find the price of the best EV in the market based on buyer sentiment.\"\n",
    "\n",
    "    agent = AutoGPTCoTAgent(max_iterations=5)\n",
    "    final_answer = agent.run(user_query)\n",
    "\n",
    "    print(\"=== FINAL ANSWER ===\")\n",
    "    print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9943c259",
   "metadata": {},
   "source": [
    "## How to Run\n",
    "1. **Run all cells** in the notebook.\n",
    "2. Check the **FINAL ANSWER** printed by the last cell. It should say something like:\n",
    "   > \"The best EV based on buyer sentiment is the Tesla Model Y, which is priced around \\$54,000.\"\n",
    "3. If you want to **debug** or see the conversation, you can print out `agent.conversation_log` after the loop.\n",
    "\n",
    "## Example Conversation Log\n",
    "You might see:\n",
    "```\n",
    "User: Find the price of the best EV in the market based on buyer sentiment.\n",
    "Agent: CHAIN_OF_THOUGHT:\n",
    "1. The user wants the best EV by buyer sentiment AND its price.\n",
    "2. First, gather sentiment...\n",
    "PLAN_TO_VISIT: [review sentiment]\n",
    "System: Searching for 'review sentiment' -> ['review_evs.com']\n",
    "System: SCRAPED review_evs.com -> Buyer Sentiment Summary...\n",
    "Agent: CHAIN_OF_THOUGHT:\n",
    "1. We know Tesla Model Y is top-rated. Still need price...\n",
    "PLAN_TO_VISIT: [price market]\n",
    "System: Searching for 'price market' -> ['auto_market.com']\n",
    "System: SCRAPED auto_market.com -> Pricing Data: Tesla Model Y...\n",
    "Agent: CHAIN_OF_THOUGHT:\n",
    "1. Found top-rated EV (Tesla Model Y) and price ($54,000)\n",
    "FINAL_ANSWER: The best EV based on buyer sentiment is the Tesla Model Y, priced at $54,000.\n",
    "```\n",
    "\n",
    "## Key Points\n",
    "1. **Explicit Chain-of-Thought**: The `CHAIN_OF_THOUGHT:` section spells out the reasoning steps.\n",
    "2. **Auto-GPT Loop**: The agent calls the LLM repeatedly, checking each time if we should **visit more sites** or **provide a final answer**.\n",
    "3. **Tool Usage**: The agent uses `web_search_tool` to find sites, then `web_scrape_tool` to get content. This content is appended to the conversation.\n",
    "4. **Iteration Limit**: We use `max_iterations=5` to avoid infinite loops.\n",
    "5. **Mocked Data**: In production, you'd replace these steps with **real** web searches, retrieval APIs, or other data sources.\n",
    "\n",
    "This approach highlights how **Chain-of-Thought** can be made **explicit** in an **Auto-GPT style** agent, facilitating transparent planning and multi-step problem-solving."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "auto_gpt_cot_demo"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
