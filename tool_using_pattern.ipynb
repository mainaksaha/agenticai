{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3eb1c35",
   "metadata": {},
   "source": [
    "# Tool-Using Helpdesk Agent Demo\n",
    "\n",
    "This notebook demonstrates a **Tool-Using Agent** pattern. We simulate a helpdesk chatbot that can call different tools:\n",
    "- **UserDirectoryTool**: checks account status\n",
    "- **KnowledgeBaseTool**: retrieves relevant support articles\n",
    "- **TicketingTool**: creates or closes helpdesk tickets\n",
    "\n",
    "We structure the code into **four sections**:\n",
    "1. **Tools** (external service stubs)\n",
    "2. **LLM Adapter** (a mock function that decides tool usage or final answer)\n",
    "3. **Helpdesk Agent** (the core logic that orchestrates tool calls)\n",
    "4. **Main Orchestration** (where we simulate a user query and run the agent)\n",
    "\n",
    "While this example resembles a \"mini\" ReAct approach, we call it a **Tool-Using Agent** because it focuses on selecting from **multiple tools** rather than the detailed chain-of-thought steps. In practice, you can adapt it to match your exact pattern or naming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9bcd07",
   "metadata": {},
   "source": [
    "## Section 1: Tools\n",
    "Here we define three **tool functions**:\n",
    "- `user_directory_tool(user_id)`: Mocks checking an account status.\n",
    "- `knowledge_base_tool(query)`: Mocks searching a knowledge base.\n",
    "- `ticketing_tool(action, description)`: Mocks creating or closing helpdesk tickets.\n",
    "\n",
    "In a real environment, these might call external APIs or databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools.py\n",
    "\n",
    "def user_directory_tool(user_id):\n",
    "    \"\"\"\n",
    "    Mock function to get user info from some directory or IAM system.\n",
    "    Returns a dict with account status and basic info.\n",
    "    \"\"\"\n",
    "    # Example mock data: user is locked out.\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"account_status\": \"locked\",\n",
    "        \"last_login\": \"2025-02-15 10:00 AM\"\n",
    "    }\n",
    "\n",
    "def knowledge_base_tool(query):\n",
    "    \"\"\"\n",
    "    Mock function to search a knowledge base.\n",
    "    Returns a short snippet from an 'article' matching the query.\n",
    "    \"\"\"\n",
    "    kb_articles = {\n",
    "        \"email lockout\": \"To resolve an email lockout, confirm the user's identity, reset the password, and unlock the account via the user portal.\",\n",
    "        \"password reset\": \"Users can reset their password by visiting the reset portal or calling the helpdesk.\"\n",
    "    }\n",
    "    # Simple keyword matching for demonstration\n",
    "    for keyword, article in kb_articles.items():\n",
    "        if keyword in query.lower():\n",
    "            return article\n",
    "    return \"No relevant knowledge base article found for that query.\"\n",
    "\n",
    "def ticketing_tool(action, description):\n",
    "    \"\"\"\n",
    "    Mock function to create or close a support ticket in a ticketing system.\n",
    "    'action' can be 'create' or 'close'.\n",
    "    \"\"\"\n",
    "    if action == \"create\":\n",
    "        return f\"Ticket created with description: '{description}'.\"\n",
    "    elif action == \"close\":\n",
    "        return f\"Ticket closed with note: '{description}'.\"\n",
    "    else:\n",
    "        return f\"Unknown ticket action '{action}'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fbb8d5",
   "metadata": {},
   "source": [
    "## Section 2: LLM Adapter\n",
    "This **mock function** simulates how an LLM might respond to prompts. It returns either a **TOOL_ACTION** (which tool to call next) or a **FINAL_ANSWER**. In production, replace `call_llm(prompt, temperature)` with real calls to LLM APIs like OpenAI, Anthropic, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e956c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_adapter.py\n",
    "\n",
    "def call_llm(prompt, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Simulated LLM call. In a production scenario, you'd send 'prompt' to an actual LLM.\n",
    "    We'll parse the conversation text for keywords and return either a 'TOOL_ACTION' or 'FINAL_ANSWER'.\n",
    "    \"\"\"\n",
    "    lower_prompt = prompt.lower()\n",
    "\n",
    "    # Check if we've already referenced user_directory_tool output\n",
    "    if \"account status\" in lower_prompt or \"locked\" in lower_prompt:\n",
    "        # Next step: reference knowledge base\n",
    "        return \"TOOL_ACTION: knowledge_base, query='email lockout'\"\n",
    "\n",
    "    elif \"knowledgebase response\" in lower_prompt:\n",
    "        # Then we create a ticket\n",
    "        return \"TOOL_ACTION: ticketing, action='create', description='User locked out of email'\"\n",
    "\n",
    "    elif \"ticket created\" in lower_prompt:\n",
    "        # Now provide final answer\n",
    "        return (\"FINAL_ANSWER: The user account was locked. We have reset the password \"\n",
    "                \"and unlocked the account. A support ticket was created to confirm resolution.\")\n",
    "\n",
    "    else:\n",
    "        # First step might be to check the user directory\n",
    "        return \"TOOL_ACTION: user_directory, user_id='U12345'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6648afc9",
   "metadata": {},
   "source": [
    "## Section 3: Helpdesk Agent\n",
    "This is where the **tool-using logic** resides. The agent:\n",
    "1. **Collects** the user query.\n",
    "2. **Calls** the LLM with the conversation so far.\n",
    "3. **Parses** the LLM response for `TOOL_ACTION` or `FINAL_ANSWER`.\n",
    "4. If it’s a tool action, **calls** the relevant tool and appends the observation, then loops again.\n",
    "5. If it’s a final answer, **concludes**.\n",
    "\n",
    "We add a maximum loop count (`max_rounds`) to avoid infinite cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8368731c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpdesk_agent.py\n",
    "\n",
    "import re\n",
    "from tools import (\n",
    "    user_directory_tool,\n",
    "    knowledge_base_tool,\n",
    "    ticketing_tool\n",
    ")\n",
    "from llm_adapter import call_llm\n",
    "\n",
    "class HelpdeskToolAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_log = []\n",
    "        self.max_rounds = 5  # to prevent infinite loops\n",
    "\n",
    "    def handle_user_issue(self, user_query: str):\n",
    "        \"\"\"\n",
    "        Main loop for a tool-using agent:\n",
    "        1. Keep prompting the LLM with conversation context.\n",
    "        2. If the LLM requests a tool, call it and record observation.\n",
    "        3. If the LLM provides a final answer, stop.\n",
    "        \"\"\"\n",
    "        # 1. Add user query to conversation\n",
    "        self.conversation_log.append(f\"User: {user_query}\")\n",
    "\n",
    "        for _ in range(self.max_rounds):\n",
    "            # 2. Build prompt from conversation log\n",
    "            prompt = \"\\n\".join(self.conversation_log) + \"\\nAgent, decide your next step.\"\n",
    "            response = call_llm(prompt)\n",
    "            self.conversation_log.append(f\"Agent: {response}\")\n",
    "\n",
    "            # 3. Check if response indicates a tool action or final answer\n",
    "            if \"TOOL_ACTION:\" in response:\n",
    "                tool_call = self.parse_tool_action(response)\n",
    "                if tool_call:\n",
    "                    # 4. Call the specified tool\n",
    "                    tool_name = tool_call[\"tool\"]\n",
    "                    kwargs = tool_call[\"kwargs\"]\n",
    "                    observation = self.call_tool(tool_name, **kwargs)\n",
    "                    self.conversation_log.append(f\"Tool Observation: {observation}\")\n",
    "                else:\n",
    "                    self.conversation_log.append(\"Tool Observation: Could not parse tool action.\")\n",
    "                    break\n",
    "\n",
    "            elif \"FINAL_ANSWER:\" in response:\n",
    "                final_answer = response.split(\"FINAL_ANSWER:\")[-1].strip()\n",
    "                return final_answer\n",
    "\n",
    "        # If we exit the loop without a FINAL_ANSWER, provide fallback\n",
    "        return \"I’m sorry, but I couldn’t resolve your request at this time.\"\n",
    "\n",
    "    def parse_tool_action(self, text):\n",
    "        \"\"\"\n",
    "        Look for lines like:\n",
    "        TOOL_ACTION: user_directory, user_id='U12345'\n",
    "        We'll parse it with a simple regex.\n",
    "        \"\"\"\n",
    "        match = re.search(r\"TOOL_ACTION:\\s*(\\w+)\\s*,\\s*(.*)\", text)\n",
    "        if not match:\n",
    "            return None\n",
    "        tool_name = match.group(1)\n",
    "        params_str = match.group(2)  # e.g. user_id='U12345'\n",
    "\n",
    "        # Extract key='value' pairs\n",
    "        kwargs = {}\n",
    "        pairs = re.findall(r\"(\\w+)='([^']*)'\", params_str)\n",
    "        for k, v in pairs:\n",
    "            kwargs[k] = v\n",
    "\n",
    "        return {\"tool\": tool_name, \"kwargs\": kwargs}\n",
    "\n",
    "    def call_tool(self, tool_name, **kwargs):\n",
    "        \"\"\"\n",
    "        Dispatch to the correct tool function.\n",
    "        \"\"\"\n",
    "        if tool_name == \"user_directory\":\n",
    "            return user_directory_tool(kwargs.get(\"user_id\", \"\"))\n",
    "        elif tool_name == \"knowledge_base\":\n",
    "            return knowledge_base_tool(kwargs.get(\"query\", \"\"))\n",
    "        elif tool_name == \"ticketing\":\n",
    "            return ticketing_tool(\n",
    "                action=kwargs.get(\"action\", \"\"),\n",
    "                description=kwargs.get(\"description\", \"\")\n",
    "            )\n",
    "        else:\n",
    "            return f\"Unknown tool '{tool_name}'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b3bf4",
   "metadata": {},
   "source": [
    "## Section 4: Main Orchestration\n",
    "We simulate a user saying they're locked out of their email. The **HelpdeskToolAgent** will decide which tool(s) to call based on the LLM responses and eventually provide a final answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d188aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    user_query = \"Hi, I'm locked out of my email account. Can you help me?\"\n",
    "\n",
    "    agent = HelpdeskToolAgent()\n",
    "    final_response = agent.handle_user_issue(user_query)\n",
    "\n",
    "    print(\"=== AGENT FINAL RESPONSE ===\")\n",
    "    print(final_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc5e0a8",
   "metadata": {},
   "source": [
    "## How to Run\n",
    "1. **Run all cells** in the notebook.\n",
    "2. The output from the final cell should display the agent’s final answer (e.g., a resolution message).\n",
    "3. You can inspect the agent’s conversation log or tweak the `user_query` to explore different scenarios.\n",
    "\n",
    "## Key Points\n",
    "1. **Multiple Tools**: The agent can invoke different tools based on context (user directory, knowledge base, ticketing system).\n",
    "2. **LLM-Driven**: The LLM decides when to use each tool by returning a `TOOL_ACTION` directive.\n",
    "3. **Conversation Loop**: Each new step includes the full conversation history (including tool observations) to guide the next LLM response.\n",
    "4. **Not Strictly ReAct**: This example is labeled as a **Tool-Using Agent** to emphasize choosing among multiple tools rather than a formal chain-of-thought structure. Still, it's conceptually similar.\n",
    "5. **Extensibility**: You can add more tools or integrate real APIs. You can also adopt structured output formats (like JSON) for more reliable parsing.\n",
    "\n",
    "Run the notebook to see how the agent arrives at a final resolution by calling the correct tools in sequence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "tool_using_helpdesk_demo"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
