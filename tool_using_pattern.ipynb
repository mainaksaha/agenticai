{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f26c2b2b",
   "metadata": {},
   "source": [
    "# Single-Pass Tool-Using Helpdesk Agent (OpenAI Version)\n",
    "\n",
    "In this notebook, we do a **single call** to OpenAI’s API to decide whether the agent:\n",
    "1. **Invokes exactly one** tool (user directory, knowledge base, or ticketing), or\n",
    "2. Provides a **final answer** without tool usage.\n",
    "\n",
    "**Tools** are **dummy**—they only return a mock message or data. The OpenAI response is used to parse out either a `TOOL_ACTION` or `FINAL_ANSWER`. No iterative loop or multiple LLM calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f38c94e",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies\n",
    "Make sure you have the `openai` library installed:\n",
    "```\n",
    "pip install openai\n",
    "```\n",
    "Also, set your **OpenAI API key** in an environment variable `OPENAI_API_KEY` or configure it in your code (not shown here for security)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=''\n",
    "\n",
    "# Optionally set your API key in code (not recommended for production)\n",
    "# openai.api_key = \"YOUR_OPENAI_API_KEY\"  # Typically better to set via environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a952300",
   "metadata": {},
   "source": [
    "## 2. Define Dummy Tools\n",
    "We create **three** placeholder functions, each returning a **mock** response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_directory_tool(user_id):\n",
    "    \"\"\"\n",
    "    Mock function to get user info from an IAM system.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"user_id\": user_id,\n",
    "        \"account_status\": \"locked\",\n",
    "        \"last_login\": \"2025-02-15 10:00 AM\"\n",
    "    }\n",
    "\n",
    "def knowledge_base_tool(query):\n",
    "    \"\"\"\n",
    "    Mock function to search a knowledge base.\n",
    "    \"\"\"\n",
    "    kb_articles = {\n",
    "        \"email lockout\": \"To resolve an email lockout, confirm the user's identity, reset the password, and unlock the account.\",\n",
    "        \"password reset\": \"Users can reset their password by visiting the reset portal or calling the helpdesk.\"\n",
    "    }\n",
    "    for keyword, article in kb_articles.items():\n",
    "        if keyword in query.lower():\n",
    "            return article\n",
    "    return \"No relevant article found.\"\n",
    "\n",
    "def ticketing_tool(action, description):\n",
    "    \"\"\"\n",
    "    Mock function to create or close a support ticket.\n",
    "    \"\"\"\n",
    "    if action == \"create\":\n",
    "        return f\"Ticket created with description: '{description}'.\"\n",
    "    elif action == \"close\":\n",
    "        return f\"Ticket closed with note: '{description}'.\"\n",
    "    else:\n",
    "        return f\"Unknown ticket action '{action}'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3124c6a3",
   "metadata": {},
   "source": [
    "## 3. OpenAI LLM Call\n",
    "We'll define a function `call_openai_for_action` that:\n",
    "1. Sends the user's **query** to OpenAI.\n",
    "2. **Instructs** the model to either produce `TOOL_ACTION:` (with details) or `FINAL_ANSWER:`.\n",
    "3. Returns the raw text from the LLM.\n",
    "\n",
    "You can tweak the system/user messages and the prompt structure to your preference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae1f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai_for_action(user_query, temperature=0.2):\n",
    "    \"\"\"\n",
    "    Calls the OpenAI API once to decide which tool to invoke or finalize an answer.\n",
    "    We expect a response containing either:\n",
    "      TOOL_ACTION: <tool_name>, param='value', ...\n",
    "      or\n",
    "      FINAL_ANSWER: <some text>\n",
    "    \"\"\"\n",
    "\n",
    "    system_message = (\n",
    "        \"You are a helpdesk AI. You have 3 possible tools to help you:\"+\n",
    "        \"1) user_directory (requires user_id='xxx')\"+\n",
    "        \"2) knowledge_base (requires query='some string')\"+\n",
    "        \"3) ticketing (requires action='create' or 'close', description='string')\"+\n",
    "        \"Decide which tool to use based on the user query, or provide a final answer.\"+\n",
    "        \"Format your reply as either:\"+\n",
    "        \"TOOL_ACTION: <tool_name>, key='value', ...\"+\n",
    "        \"or\"+\n",
    "        \"FINAL_ANSWER: <text>\"\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ]\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  # or 'text-davinci-003', depending on your plan\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    raw_text = response.choices[0].message.content\n",
    "    print(raw_text)\n",
    "    return raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2461bc",
   "metadata": {},
   "source": [
    "## 4. Single-Pass Helpdesk Agent\n",
    "We define a class that:\n",
    "1. Receives a user query.\n",
    "2. Makes a **single call** to `call_openai_for_action(...)`.\n",
    "3. If the returned text starts with `TOOL_ACTION:`, it parses out the tool name and parameters, calls the dummy tool, and returns the observation.\n",
    "4. If it starts with `FINAL_ANSWER:`, it just returns that.\n",
    "5. If neither is found, a fallback message is given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67c00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelpdeskToolAgent:\n",
    "    def __init__(self):\n",
    "        self.conversation_log = []\n",
    "\n",
    "    def handle_user_query(self, user_query: str):\n",
    "        # Log user query\n",
    "        self.conversation_log.append(f\"User: {user_query}\")\n",
    "\n",
    "        # Call OpenAI to decide on a tool or final answer\n",
    "        llm_response = call_openai_for_action(user_query)\n",
    "        self.conversation_log.append(f\"LLM: {llm_response}\")\n",
    "\n",
    "        # Check for TOOL_ACTION or FINAL_ANSWER\n",
    "        if \"TOOL_ACTION:\" in llm_response:\n",
    "            action_str = llm_response.split(\"TOOL_ACTION:\")[-1].strip()\n",
    "            return self._invoke_tool(action_str)\n",
    "\n",
    "        elif \"FINAL_ANSWER:\" in llm_response:\n",
    "            return llm_response.split(\"FINAL_ANSWER:\")[-1].strip()\n",
    "\n",
    "        # fallback\n",
    "        return \"Could not parse a tool action or final answer.\"\n",
    "\n",
    "    def _invoke_tool(self, action_str):\n",
    "        # We expect something like: \"user_directory, user_id='U9999'\"\n",
    "        # or: \"ticketing, action='create', description='...'\"\n",
    "\n",
    "        # Let's parse out the tool name first\n",
    "        parts = action_str.split(\",\")\n",
    "        tool_name = parts[0].strip()\n",
    "        # The rest are key='value' pairs\n",
    "        kwargs = {}\n",
    "        if len(parts) > 1:\n",
    "            # e.g. key='value', key2='value2'\n",
    "            param_str = \",\".join(parts[1:])\n",
    "            matches = re.findall(r\"(\\w+)='([^']*)'\", param_str)\n",
    "            for k, v in matches:\n",
    "                kwargs[k] = v\n",
    "\n",
    "        # Call the corresponding dummy tool\n",
    "        if tool_name == \"user_directory\":\n",
    "            result = user_directory_tool(kwargs.get(\"user_id\", \"\"))\n",
    "            return f\"Tool invoked: {tool_name}\\nResult: {result}\"\n",
    "        elif tool_name == \"knowledge_base\":\n",
    "            result = knowledge_base_tool(kwargs.get(\"query\", \"\"))\n",
    "            return f\"Tool invoked: {tool_name}\\nResult: {result}\"\n",
    "        elif tool_name == \"ticketing\":\n",
    "            result = ticketing_tool(\n",
    "                action=kwargs.get(\"action\", \"\"),\n",
    "                description=kwargs.get(\"description\", \"\")\n",
    "            )\n",
    "            return f\"Tool invoked: {tool_name}\\nResult: {result}\"\n",
    "        else:\n",
    "            return f\"Unknown tool '{tool_name}'.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e71ea8",
   "metadata": {},
   "source": [
    "## 5. Main Orchestration\n",
    "We create the agent, provide a **sample** user query (e.g., “I’m locked out of my email”), and print the **single** response. The LLM might say “TOOL_ACTION: user_directory, user_id='U9999'” or “FINAL_ANSWER: ...”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481c9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    agent = HelpdeskToolAgent()\n",
    "\n",
    "    sample_query = \"Hi, I'm locked out of my email account. How can I fix this?\"\n",
    "    response = agent.handle_user_query(sample_query)\n",
    "    print(\"=== SINGLE-PASS HELPDESK RESPONSE ===\")\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebedbcf6",
   "metadata": {},
   "source": [
    "## Usage Notes\n",
    "1. **API Key**: Make sure you have `OPENAI_API_KEY` set as an environment variable (or set `openai.api_key` in code). Without it, the call will fail.\n",
    "2. **Model**: We use `gpt-3.5-turbo` in `openai.ChatCompletion.create`. If you have access to GPT-4, you can switch to `gpt-4`. Or if you prefer a completion model, adapt the code accordingly.\n",
    "3. **Prompt Engineering**: The system prompt instructs the model to choose a tool from `[user_directory, knowledge_base, ticketing]` or provide a final answer.\n",
    "4. **Dummy Tools**: We only show mock returns from `user_directory_tool`, `knowledge_base_tool`, `ticketing_tool`. In reality, you’d integrate actual APIs.\n",
    "5. **Single Pass**: This approach does exactly **one** LLM call, so it won't do multiple steps or reevaluate after tool usage. If you need that, consider a multi-step agent with memory or reflection.\n",
    "\n",
    "## Example Output\n",
    "A typical run (with certain prompt/response) might yield:\n",
    "```\n",
    "=== SINGLE-PASS HELPDESK RESPONSE ===\n",
    "Tool invoked: user_directory\n",
    "Result: {'user_id': 'U9999', 'account_status': 'locked', 'last_login': '2025-02-15 10:00 AM'}\n",
    "```\n",
    "indicating that the LLM recommended we check the user directory for a locked account. Alternatively, it might produce a final answer saying no tool is needed if it doesn’t see relevant keywords.\n",
    "\n",
    "## Key Takeaways\n",
    "1. **OpenAI Integration**: This code makes a single call to `openai.ChatCompletion.create(...)`.\n",
    "2. **One Tool / One Response**: We parse out `TOOL_ACTION:` from the LLM's text and call the corresponding function. Otherwise, we return the `FINAL_ANSWER:`.\n",
    "3. **Expandable**: In production, you might keep a **registry** of available tools, handle more complex parameters, or incorporate multi-step logic if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "name": "single_pass_tool_using_helpdesk_openai"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
